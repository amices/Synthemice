%  LaTeX support: latex@mdpi.com
%  In case you need support, please attach all files that are necessary for compiling as well as the log file, and specify the details of your LaTeX setup (which operating system and LaTeX version / tools you are using).

%=================================================================
\documentclass[psych,article,submit,moreauthors,pdftex]{mdpi}

% If you would like to post an early version of this manuscript as a preprint, you may use preprint as the journal and change 'submit' to 'accept'. The document class line would be, e.g., \documentclass[preprints,article,accept,moreauthors,pdftex]{mdpi}. This is especially recommended for submission to arXiv, where line numbers should be removed before posting. For preprints.org, the editorial staff will make this change immediately prior to posting.

%% Some pieces required from the pandoc template
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{4pt}}
\setlist[itemize]{leftmargin=*,labelsep=5.8mm}
\setlist[enumerate]{leftmargin=*,labelsep=4.9mm}

\usepackage{longtable}

% see https://stackoverflow.com/a/47122900
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}

%--------------------
% Class Options:
%--------------------
%----------
% journal
%----------
% Choose between the following MDPI journals:
% acoustics, actuators, addictions, admsci, aerospace, agriculture, agriengineering, agronomy, algorithms, animals, antibiotics, antibodies, antioxidants, applsci, arts, asc, asi, atmosphere, atoms, axioms, batteries, bdcc, behavsci , beverages, bioengineering, biology, biomedicines, biomimetics, biomolecules, biosensors, brainsci , buildings, cancers, carbon , catalysts, cells, ceramics, challenges, chemengineering, chemistry, chemosensors, children, cleantechnol, climate, clockssleep, cmd, coatings, colloids, computation, computers, condensedmatter, cosmetics, cryptography, crystals, dairy, data, dentistry, designs , diagnostics, diseases, diversity, drones, econometrics, economies, education, electrochem, electronics, energies, entropy, environments, epigenomes, est, fermentation, fibers, fire, fishes, fluids, foods, forecasting, forests, fractalfract, futureinternet, futurephys, galaxies, games, gastrointestdisord, gels, genealogy, genes, geohazards, geosciences, geriatrics, hazardousmatters, healthcare, heritage, highthroughput, horticulturae, humanities, hydrology, ijerph, ijfs, ijgi, ijms, ijns, ijtpp, informatics, information, infrastructures, inorganics, insects, instruments, inventions, iot, j, jcdd, jcm, jcp, jcs, jdb, jfb, jfmk, jimaging, jintelligence, jlpea, jmmp, jmse, jnt, jof, joitmc, jpm, jrfm, jsan, land, languages, laws, life, literature, logistics, lubricants, machines, magnetochemistry, make, marinedrugs, materials, mathematics, mca, medicina, medicines, medsci, membranes, metabolites, metals, microarrays, micromachines, microorganisms, minerals, modelling, molbank, molecules, mps, mti, nanomaterials, ncrna, neuroglia, nitrogen, notspecified, nutrients, ohbm, particles, pathogens, pharmaceuticals, pharmaceutics, pharmacy, philosophies, photonics, physics, plants, plasma, polymers, polysaccharides, preprints , proceedings, processes, proteomes, psych, publications, quantumrep, quaternary, qubs, reactions, recycling, religions, remotesensing, reports, resources, risks, robotics, safety, sci, scipharm, sensors, separations, sexes, signals, sinusitis, smartcities, sna, societies, socsci, soilsystems, sports, standards, stats, surfaces, surgeries, sustainability, symmetry, systems, technologies, test, toxics, toxins, tropicalmed, universe, urbansci, vaccines, vehicles, vetsci, vibration, viruses, vision, water, wem, wevj

%---------
% article
%---------
% The default type of manuscript is "article", but can be replaced by:
% abstract, addendum, article, benchmark, book, bookreview, briefreport, casereport, changes, comment, commentary, communication, conceptpaper, conferenceproceedings, correction, conferencereport, expressionofconcern, extendedabstract, meetingreport, creative, datadescriptor, discussion, editorial, essay, erratum, hypothesis, interestingimages, letter, meetingreport, newbookreceived, obituary, opinion, projectreport, reply, retraction, review, perspective, protocol, shortnote, supfile, technicalnote, viewpoint
% supfile = supplementary materials

%----------
% submit
%----------
% The class option "submit" will be changed to "accept" by the Editorial Office when the paper is accepted. This will only make changes to the frontpage (e.g., the logo of the journal will get visible), the headings, and the copyright information. Also, line numbering will be removed. Journal info and pagination for accepted papers will also be assigned by the Editorial Office.

%------------------
% moreauthors
%------------------
% If there is only one author the class option oneauthor should be used. Otherwise use the class option moreauthors.

%---------
% pdftex
%---------
% The option pdftex is for use with pdfLaTeX. If eps figures are used, remove the option pdftex and use LaTeX and dvi2pdf.

%=================================================================
\firstpage{1}
\makeatletter
\setcounter{page}{\@firstpage}
\makeatother
\pubvolume{xx}
\issuenum{1}
\articlenumber{5}
\pubyear{2019}
\copyrightyear{2019}
%\externaleditor{Academic Editor: name}
\history{Received: date; Accepted: date; Published: date}
\updates{yes} % If there is an update available, un-comment this line

%% MDPI internal command: uncomment if new journal that already uses continuous page numbers
%\continuouspages{yes}

%------------------------------------------------------------------
% The following line should be uncommented if the LaTeX file is uploaded to arXiv.org
%\pdfoutput=1

%=================================================================
% Add packages and commands here. The following packages are loaded in our class file: fontenc, calc, indentfirst, fancyhdr, graphicx, lastpage, ifthen, lineno, float, amsmath, setspace, enumitem, mathpazo, booktabs, titlesec, etoolbox, amsthm, hyphenat, natbib, hyperref, footmisc, geometry, caption, url, mdframed, tabto, soul, multirow, microtype, tikz

%=================================================================
%% Please use the following mathematics environments: Theorem, Lemma, Corollary, Proposition, Characterization, Property, Problem, Example, ExamplesandDefinitions, Hypothesis, Remark, Definition
%% For proofs, please use the proof environment (the amsthm package is loaded by the MDPI class).

%=================================================================
% Full title of the paper (Capitalized)
\Title{Anony\emph{mice}d shareable data: Using \emph{mice} to create and
analyze multiply imputed synthetic data sets}

% Authors, for the paper (add full first names)
\Author{Thom
Volker$^{1,*}$\href{https://orcid.org/0000-0003-3293-2315}{\orcidicon}, Gerko
Vink$^{1,
\dagger}$\href{https://orcid.org/0000-0001-9767-1924}{\orcidicon}}

% Authors, for metadata in PDF
\AuthorNames{Thom Volker, Gerko Vink}

% Affiliations / Addresses (Add [1] after \address if there is only one affiliation.)
\address{%
$^{1}$ \quad Utrecht University - Department of Methodology and
Statistics Padualaan 14, 3584CH Utrecht, the Netherlands; \\
}
% Contact information of the corresponding author
\corres{Correspondence: \href{mailto:t.b.volker@uu.nl}{\nolinkurl{t.b.volker@uu.nl}}.}

% Current address and/or shared authorship
\firstnote{These authors contributed equally to this work.}







% The commands \thirdnote{} till \eighthnote{} are available for further notes

% Simple summary
\simplesumm{A Simple summary goes here.}

% Abstract (Do not insert blank lines, i.e. \\)
\abstract{A single paragraph of about 200 words maximum. For research
articles, abstracts should give a pertinent overview of the work. We
strongly encourage authors to use the following style of structured
abstracts, but without headings: 1) Background: Place the question
addressed in a broad context and highlight the purpose of the study; 2)
Methods: Describe briefly the main methods or treatments applied; 3)
Results: Summarize the article's main findings; and 4) Conclusion:
Indicate the main conclusions or interpretations. The abstract should be
an objective representation of the article, it must not contain results
which are not presented and substantiated in the main text and should
not exaggerate the main conclusions.}

% Keywords
\keyword{keyword 1; keyword 2; keyword 3 (list three to ten pertinent
keywords specific to the article, yet reasonably common within the
subject discipline.).}

% The fields PACS, MSC, and JEL may be left empty or commented out if not applicable
%\PACS{J0101}
%\MSC{}
%\JEL{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Diversity
%\LSID{\url{http://}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Applied Sciences:
%\featuredapplication{Authors are encouraged to provide a concise description of the specific application or a potential application of the work. This section is not mandatory.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Data:
%\dataset{DOI number or link to the deposited data set in cases where the data set is published or set to be published separately. If the data set is submitted and will be published as a supplement to this paper in the journal Data, this field will be filled by the editors of the journal. In this case, please make sure to submit the data set as a supplement when entering your manuscript into our manuscript editorial system.}

%\datasetlicense{license under which the data set is made available (CC0, CC-BY, CC-BY-SA, CC-BY-NC, etc.)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Toxins
%\keycontribution{The breakthroughs or highlights of the manuscript. Authors can write one or two sentences to describe the most important part of the paper.}

%\setcounter{secnumdepth}{4}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Pandoc citation processing

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}

\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Open science, including open data, has been marked as the future of
science \citep{gewin_data_2016}, and the advantages of publicly
available research data are numerous
\citep{molloy_open_2011, walport_brest_sharing_2011}. Collecting
research data requires an enormous investment both in terms of time and
monetary resources. Openly accessible research data bears the potential
of increasing the scientific returns for the same data collection
effort. Additionally, the fact that public funds are used for data
collection results in increasing demand for the collected data.
Nevertheless, the possibilities to distribute research data directly are
often very limited due to restrictions on data privacy and data
confidentiality. Although these regulations are much needed, privacy
constraints are also ranked among the toughest challenges to overcome in
the advancement of modern day social science research
\citep{lazer_life_2009}.

Anonymizing research data might seem a quick and appealing approach to
limit the unique identification of participants. However, this approach
is not sufficient to fulfil contemporary privacy and confidentiality
requirements \citep{ohm_broken_2009, national_putting_2007}. Over the
years, several other techniques have been used to increase the
confidentiality of research data, such as categorizing continuous
variables, top coding values above an upper bound or adding random noise
to the observed values \citep{drechsler_synthetic_2011}. However, these
methods may distort the true data relation between variables, thereby
reducing the data quality and the scientific returns for re-using the
same data for further research.

An alternative solution has been proposed separately by
\citet{rubin_statistical_disclosure_1993} and
\citet{little_statistical_1993}. Although their approaches differ to
some extent, the overarching procedure is to use bonafide observed data
to generate multiply imputed synthetic data sets that can be freely
disclosed. While in practice, one could see this as replacing the
observed data values by multiple draws from the posterior predictive
distribution of the observed data, based on some imputation model, Rubin
would argue that these synthetic data values are merely draws from the
same true data generating model. In that sense, the observed data is
never replaced, but the population is resampled from the information
captured in the (incomplete) sample. Using this approach, the researcher
could replace the observed data set as a whole with multiple synthetic
versions. Alternatively, the researcher could opt to only replace a
subset of the observed data. For example, one can choose to only replace
dimensions in the data that could be compared with publicly available
data sets or registers. Likewise, synthetisation could be limited to
those values that are disclosive, such as high incomes or high
turnovers.

Conceptually, the synthetic data framework is based upon the building
blocks of multiple imputation of missing data, as proposed by
\citet{rubin_multiple_1987}. Instead of replacing just the missing
values with multiple draws from the posterior predictive distribution,
one could easily \emph{overimpute} any observed sensitive values.
Similarly to multiple imputation of missing data, the multiple synthetic
data sets allow for correct statistical inferences, despite the fact
that the analyses do not use the ``true'' value. The analyses over
multiple synthetic data sets should be pooled into a single inference,
so that the researcher can draw valid conclusions from the pooled
results. To that respect, the variance should reflect the added
variability that is induced by the imputation procedure.

Potentially, this approach could fulfill the needs for openly accessibly
data, without running into barriers with regard to privacy and
confidentiality constraints. However, there is no such thing as a free
lunch: data collectors have to put effort in creating high-quality
synthetic data. Also, the quality of the synthetic data is highly
dependent on the imputation models, and using flawed models to generate
synthetic data might bias subsequent analyses. Conversely, if the models
used to create the synthetic data are able to preserve the relationships
between the variables as in the original data, the synthetic data can be
nearly as informative as the observed data. Thus, to fully exploit the
benefits of synthetic data, the effort to actually create these
high-quality data sets should be kept at a minimum.

To mitigate additional effort of creating synthetic data sets on behalf
of the researcher, software aimed at multiple imputation of missing data
can be employed. Especially if researchers used this software at an
earlier stage in the research process, or acquired familiarity with it
during earlier projects, the additional burden of creating synthetic
data sets is relatively small. The R-package \texttt{mice} \citep{mice}
implements multiple imputation of missing data in a straightforward and
user-friendly manner. However, the functionality of \texttt{mice} is not
restricted to the imputation of missing data, but allows to impute any
value in the data: even observed values. Consequently, \texttt{mice} can
be utilized for the creation of multiply imputed synthetic data sets.

After creating the multiply imputed synthetic data sets, the goal is to
obtain valid statistical inferences in the spirit of
\citet{rubin_multiple_1987} and \citet{neyman1934}. In the missing data
framework, this is done by performing statistical analyses on all
imputed data sets, and pooling the results of the analyses according to
Rubin's rules \citep[pp.76]{rubin_multiple_1987}. In the synthetic data
framework, the same procedure is followed, but with a slight twist:
there are no values that remain constant over the synthetic data sets.
The procedure of drawing valid inferences from multiple synthetic data
sets is therefore slightly different.

In this manuscript we detail a workflow for synthesizing data with
\texttt{mice}. First, the \texttt{mice} algorithm for the creation of
synthetic data will be shortly explained. The aim is to generate
synthetic sets that reassure the privacy and confidentiality of the
participants. Second, a straightforward workflow for imputation of
synthetic data with \texttt{mice} will be demonstrated. Third, we
demonstrate the validity of the procedure through statistical
simulation.

\hypertarget{generating-synthetic-data-with-mice}{%
\section{\texorpdfstring{Generating synthetic data with
\texttt{mice}}{Generating synthetic data with mice}}\label{generating-synthetic-data-with-mice}}

The \texttt{mice} package \citep{mice} in \texttt{R} \citep{Rproject}
has been developed for multiple imputation of missing data. In this
context, the aim is to replace missing values due to nonresponse by
plausible values from the posterior predictive distribution of the
variable containing the missings. Doing so, \texttt{mice} makes use of
fully conditional specification {[}FCS; \citet{vanbuuren_fully_2006}{]},
which breaks down the multivariate distribution of the data
\(\textbf{Y} = (\textbf{Y}_{obs}, \textbf{Y}_{mis})\) into
\(j = 1, 2, \dots, k\) univariate conditional densities, where \(k\)
denotes the number of columns in the data. Using FCS, a model is
constructed for every incomplete variable and the missing values
\(Y_{j, mis}\) are then imputed with draws from the posterior predictive
distribution of \(P(Y_{j, mis} | \textbf{Y}_{obs}, \theta)\) on a
variable-by-variable basis. Note that the predictor matrix \(Y_{-j}\)
may contain yet imputed values from an earlier imputation step, and thus
will be updated after every iteration. This procedure is applied \(m\)
times, resulting in \(m\) completed data sets
\(\textbf{D} = (\textbf{D}^{(1)}, \textbf{D}^{(2)}, \dots, \textbf{D}^{(m)})\),
with \(\textbf{D}^{(l)} = (\textbf{Y}_{obs}, Y^{(l)}_{mis})\).

In \texttt{mice}, the generation of multiply imputed data sets to solve
for unobserved values is straightforward. The following pseudocode
details the multiple imputation of the \texttt{mice::boys} data set
\citep{fredriks_boys_2000} into the object \texttt{imp} with
\texttt{m\ =\ 10} imputated sets and \texttt{maxit\ =\ 7} iterations for
the algorithm to converge, using the default imputations methods for
each column data class.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(mice)}
\NormalTok{imp }\OtherTok{\textless{}{-}} \FunctionTok{mice}\NormalTok{(boys, }
            \AttributeTok{m =} \DecValTok{10}\NormalTok{,}
            \AttributeTok{maxit =} \DecValTok{7}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

It is straightforward to extended the imputation approach to generate
synthetic values. Rather than imputing missing data, the observed values
are then replaced by synthetic draws from the posterior predictive
distribution. For simplicity, assume that the data is completely
observed (i.e., \(\textbf{Y} = \textbf{Y}_{obs}\)). Following the
notation of \citet{reiter_raghunathan_multiple_2007}, let for \(n\)
units denote \(Z_i = 1\) if any of the values of unit
\(i = 1, 2, \dots, n\) are to be replaced by imputations, and
\(Z_i = 0\) otherwise, with \(\textbf{Z} = (Z_1, Z_2, \dots, Z_n)\).
Accordingly, the data consists of values that are to be replaced and
values that are to be kept (i.e.,
\(\textbf{Y} = (\textbf{Y}_{rep}, \textbf{Y}_{nrep})\). Now, instead of
imputing \(\textbf{Y}_{mis}\) with draws from the posterior predictive
distribution of \(P(Y_{j, mis} | \textbf{Y}_{obs}, \theta)\) as in the
missing data case, \(\textbf{Y}_{rep}\) is imputed from the posterior
distribution of
\(P(Y^{(l)}_{j, rep} | \textbf{Y}^{(l)}_{-j}, \textbf{Z}, \theta)\),
where \(l\) is an indicator for the synthetic data set
(\(l = 1, 2, \dots, m\)). Note that synthetic values that are imputed at
an earlier step can be used for imputing variable \(j\). This process
results in the synthetic data
\(\textbf{D} = (\textbf{D}^{(1)}, \textbf{D}^{(2)}, \dots, \textbf{D}^{(m)})\).

For example, overimputing synthetic values for both the observed and
missing cells in the \texttt{mice::boys} data set into the object
\texttt{syn}, given the same imputation parameters as before, can be
realized by the following code execution.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{syn }\OtherTok{\textless{}{-}} \FunctionTok{mice}\NormalTok{(boys, }
            \AttributeTok{m =} \DecValTok{10}\NormalTok{,}
            \AttributeTok{maxit =} \DecValTok{7}\NormalTok{, }
            \AttributeTok{where =} \FunctionTok{matrix}\NormalTok{(}\ConstantTok{TRUE}\NormalTok{, }
                           \AttributeTok{nrow =} \FunctionTok{nrow}\NormalTok{(boys),}
                           \AttributeTok{ncol =} \FunctionTok{ncol}\NormalTok{(boys)))}
\end{Highlighting}
\end{Shaded}

where the argument \texttt{where} requires a matrix of the same
dimensions as the data, (i.e., a \(n \times k\) matrix) containing
logicals \(z_{ij}\) that indicate which cells are selected to have their
values replaced by draws from the posterior predictive distribution.
This approach allows to \emph{overimpute} a subset of the observed data,
or - as in the above example - the observed data as a whole, resulting
in a data set that partly or completely consists of synthetic data
values.

Choosing an adequate imputation model to impute the data is paramount,
as a flawed imputation model may drastically impact the validity of
inferences. Imputation models should be as flexible as possible to
capture most of the patterns in the data, and to model possibly
unanticipated data characteristics
\citep{murray_multiple_2018, rubin_18years_1996}. Parametric methods,
albeit easy to implement in practice, may be too restrictive to capture
generally complex patterns in the data, especially in the case of
nonlinear relations and interactions between multiple variables.
Classification and regression trees {[}CART;
\citet{breiman_cart_1984}{]} allow to model more complex patterns in the
data, and have therefore been suggested as an appropriate imputation
method
\citep{reiter_cart_2005, burgette_reiter_cart_2010, doove_buuren_recursive_2014}.
Loosely speaking, CART sequentially splits the predictor space into
non-overlapping regions in such a way that the within-region variance is
as small as possible after every split. As such, CART does not impose
any parametric distribution on the data, making it a widely applicable
method that allows for a large variety of relationships within the data
\citep{islr_2013}. Given these appealing characteristics and the call
for the use of flexible methods when multiply imputing data, we will
focus our illustrations and evaluations of \texttt{mice} to method
\texttt{mice.impute.cart()}, realized by:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{syn }\OtherTok{\textless{}{-}} \FunctionTok{mice}\NormalTok{(boys, }
            \AttributeTok{m =} \DecValTok{10}\NormalTok{,}
            \AttributeTok{maxit =} \DecValTok{7}\NormalTok{, }
            \AttributeTok{method =} \StringTok{"cart"}\NormalTok{,}
            \AttributeTok{where =} \FunctionTok{matrix}\NormalTok{(}\ConstantTok{TRUE}\NormalTok{, }
                           \AttributeTok{nrow =} \FunctionTok{nrow}\NormalTok{(boys),}
                           \AttributeTok{ncol =} \FunctionTok{ncol}\NormalTok{(boys)))}
\end{Highlighting}
\end{Shaded}

In a nutshell, the above code shows the simplicity of creating
\(m = 10\) synthetic data sets using \texttt{mice}. In practice,
however, one should take some additional complicating factors into
account. For example, one should account for deterministic relations in
the data. Additionally, relations between variables may be described
best using a different model than \texttt{CART}. Such factors are data
dependent and should be considered by the imputer. In the next section,
we will describe how the \texttt{boys} data can be adequately imputed.
Additionally, we will show through simulations that this approach yields
valid inferences.

\hypertarget{materials-and-methods}{%
\section{Materials and Methods}\label{materials-and-methods}}

We demonstrate the suitability of using \texttt{mice} for synthesization
using a simulation study on the \texttt{mice::boys} data set. This data
set consists of the values of \(748\) Dutch boys on the following \(9\)
variables:

\begin{longtable}[]{@{}ll@{}}
\toprule
column & description \\
\midrule
\endhead
age & age in years \\
hgt & height (cm) \\
wgt & weight (kg) \\
bmi & body mass index \\
hc & head circumference (cm) \\
gen & genital Tanner stage G1-G5 \\
phb & pubic hair Tanner P1-P6 \\
tv & testicular volume (ml) \\
reg & region \\
\bottomrule
\end{longtable}

Unfortunately, this data set does not differ from the vast majority of
collected data sets, in the sense that it suffers from missing data. For
simplicity, the data is completed using the default \texttt{mice}
imputation model for all predictors except \texttt{bmi}, which is
passively imputed using its deterministic relation with weight and
height.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# create a single imputed, completely observed \textasciigrave{}boys\textasciigrave{} data set}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}

\NormalTok{meth }\OtherTok{\textless{}{-}} \FunctionTok{make.method}\NormalTok{(boys)}
\NormalTok{meth[}\StringTok{"bmi"}\NormalTok{] }\OtherTok{\textless{}{-}} \StringTok{"\textasciitilde{} I(wgt / (hgt / 100)\^{}2)"}
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{make.predictorMatrix}\NormalTok{(boys)}
\NormalTok{pred[}\FunctionTok{c}\NormalTok{(}\StringTok{"hgt"}\NormalTok{, }\StringTok{"wgt"}\NormalTok{), }\StringTok{"bmi"}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{0}

\NormalTok{imp }\OtherTok{\textless{}{-}} \FunctionTok{mice}\NormalTok{(boys, }
            \AttributeTok{m =} \DecValTok{1}\NormalTok{,}
            \AttributeTok{maxit =} \DecValTok{10}\NormalTok{,}
            \AttributeTok{method =}\NormalTok{ meth,}
            \AttributeTok{predictorMatrix =}\NormalTok{ pred)}

\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{complete}\NormalTok{(imp)}
\end{Highlighting}
\end{Shaded}

\hypertarget{simulation-methods}{%
\subsection{Simulation methods}\label{simulation-methods}}

To induce sampling variance, 1000 bootstrap samples of the \texttt{boys}
data have been synthesized with \(m = 5\) imputations for every data
cell. Synthetic values are generated using the \texttt{CART} imputation
method for all columns, except for \texttt{bmi}. The deterministic
relation \texttt{bmi} which will be synthesized passively based on the
synthetic values for \texttt{hgt} and \texttt{wgt} to preserve the
relation in the synthetic data. Additional parameters that come with the
use of \texttt{mice.impute.cart()} are the complexity parameter
\texttt{cp} and the minimum number of observations in any terminal node
\texttt{minbucket}, that both constrain the flexibility of the
imputation model. The values of the parameters \texttt{cp} and
\texttt{minbucket} ought to adhere to the call for imputation models
that are as flexible as possible. Appropriate values for these
parameters, as well as the input for the \texttt{predictorMatrix},
depend on the data at hand. In the current example, the complexity
parameter is specified at \texttt{cp\ =\ 1e-08} rather than the default
value \texttt{1e-04}, and the minimum number of observations in each
terminal node is set at \texttt{minbucket} \(= 3\) rather than the
default value \(5\). By allowing for more complexity in the imputation
model, bias in the estimates from the synthetic data set is reduced.
Additionally, since the missingness pattern is monotone, the number of
iterations can be set to \texttt{maxit\ =\ 1}.

To assess the performance of \texttt{mice} for synthesizing data, we
compare the bootstrapped samples with the synthetic versions of these
bootstrapped samples. Specifically, univariate descriptive statistics,
the correlation matrix, and two linear regression models as well as one
ordered logistic regression model will be considered. Subsequently, the
bias in the parameters and the \(95\%\) confidence interval coverage of
the synthetic data will be examined. Similarly to multiple imputation of
missing data, correct inferences from synthetic data requires correct
pooling over the multiply imputed data sets.

Obtaining a final point estimate of the parameter of interest \(Q\)
after imputation is fairly easy and no different from pooling in the
case of missing data \citep{rubin_multiple_1987}. One can calculate the
average of the \(m\) point estimates \(q^{(l)}\) \[
\bar{q}_m = \sum_{l = 1}^m \frac{q^{(l)}}{m}.
\] with \(l = 1, \dots, m\).

Similarly to the missing data case, variances, and subsequently
confidence intervals, should incorporate the increase in variance that
is due to imputation
\citep{reiter_partially_inference_2003, drechsler_synthetic_2011}. Yet,
the increase in variance due to imputation differs according to whether
missing values are imputed or observed data is overimputed with missing
values. Whereas the variance estimate after imputation of missing data
needs to account for the fact that a certain amount of information in
the data is missing, variance estimation from synthetic data does not
suffer from this issue. The adjusted variance estimate that follows from
using multiple synthetic data sets only suffers from the fact that a
finite number of \(m\) synthetic data sets are used to resemble the
observed data. Hence, the according variance estimate for synthetic data
as developed by \citet{reiter_partially_inference_2003} yields \[
T = \bar{u}_m + \frac{b_m}{m},
\]

with between-imputation variance

\[
b_m = \sum_{l = 1}^m \frac{(q^{(l)} - \bar{q}_m)^2}{(m - 1)}, \\
\] and sampling variance

\[
\bar{u}_m = \sum_{l = 1} \frac{u^{(l)}}{m},
\] where \(u^{(l)}\) denotes the variance estimate in the \(l\)th
synthetic data set.

\hypertarget{results}{%
\section{Results}\label{results}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plan}\NormalTok{(multisession) }\CommentTok{\# increase speed through futures}

\NormalTok{true\_model\_age }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(age }\SpecialCharTok{\textasciitilde{}}\NormalTok{ wgt }\SpecialCharTok{+}\NormalTok{ hgt, data) }\CommentTok{\# model 1}
\NormalTok{true\_model\_wgt }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(wgt }\SpecialCharTok{\textasciitilde{}}\NormalTok{ age }\SpecialCharTok{+}\NormalTok{ hgt, data) }\CommentTok{\# model 2}
\NormalTok{true\_model\_gen }\OtherTok{\textless{}{-}}\NormalTok{ MASS}\SpecialCharTok{::}\FunctionTok{polr}\NormalTok{(gen }\SpecialCharTok{\textasciitilde{}}\NormalTok{ age }\SpecialCharTok{+}\NormalTok{ hc }\SpecialCharTok{+}\NormalTok{ reg, data, }\AttributeTok{Hess =} \ConstantTok{TRUE}\NormalTok{) }\CommentTok{\# model 3}

\NormalTok{coefs\_age }\OtherTok{\textless{}{-}}\NormalTok{ broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{(true\_model\_age)}\SpecialCharTok{$}\NormalTok{estimate }\CommentTok{\# extract coefficients of model 1}
\NormalTok{coefs\_wgt }\OtherTok{\textless{}{-}}\NormalTok{ broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{(true\_model\_wgt)}\SpecialCharTok{$}\NormalTok{estimate }\CommentTok{\# extract coefficients of model 2}
\NormalTok{coefs\_gen }\OtherTok{\textless{}{-}}\NormalTok{ broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{(true\_model\_gen)}\SpecialCharTok{$}\NormalTok{estimate }\CommentTok{\# extract coefficients of model 3}

\NormalTok{nsim }\OtherTok{\textless{}{-}} \DecValTok{1000} \CommentTok{\# use 1000 iterations}

\NormalTok{bootstrap\_samples }\OtherTok{\textless{}{-}} 
\NormalTok{  modelr}\SpecialCharTok{::}\FunctionTok{bootstrap}\NormalTok{(}\AttributeTok{data =}\NormalTok{ data, }\AttributeTok{n =}\NormalTok{ nsim) }\SpecialCharTok{\%$\%} 
\NormalTok{  strap }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{map}\NormalTok{(as\_tibble)}

\NormalTok{post }\OtherTok{\textless{}{-}} \FunctionTok{make.post}\NormalTok{(data)}
\NormalTok{post[}\StringTok{"bmi"}\NormalTok{] }\OtherTok{\textless{}{-}} \StringTok{"imp[[j]][, i] \textless{}{-} imp[[\textquotesingle{}wgt\textquotesingle{}]][, i] / (imp[[\textquotesingle{}hgt\textquotesingle{}]][, i] / 100)\^{}2"}

\NormalTok{synthetic\_samples }\OtherTok{\textless{}{-}} 
\NormalTok{  bootstrap\_samples }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{future\_map}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{    x }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mice}\NormalTok{(}\AttributeTok{m =} \DecValTok{5}\NormalTok{, }
               \AttributeTok{maxit =} \DecValTok{1}\NormalTok{,}
               \AttributeTok{method =} \StringTok{"cart"}\NormalTok{,}
               \AttributeTok{minbucket =} \DecValTok{3}\NormalTok{,}
               \AttributeTok{cp =} \FloatTok{1e{-}08}\NormalTok{,}
               \AttributeTok{predictorMatrix =}\NormalTok{ pred,}
               \AttributeTok{post =}\NormalTok{ post,}
               \AttributeTok{where =} \FunctionTok{matrix}\NormalTok{(}\ConstantTok{TRUE}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(data), }\FunctionTok{ncol}\NormalTok{(data)),}
               \AttributeTok{print =}\NormalTok{ F)}
\NormalTok{\}, }\AttributeTok{.options =} \FunctionTok{furrr\_options}\NormalTok{(}\AttributeTok{seed =} \FunctionTok{as.integer}\NormalTok{(}\DecValTok{123}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

This section may be divided by subheadings. It should provide a concise
and precise description of the experimental results, their
interpretation as well as the experimental conclusions that can be
drawn.

\hypertarget{subsection-heading-here}{%
\subsection{Subsection Heading Here}\label{subsection-heading-here}}

Subsection text here.

\hypertarget{subsubsection-heading-here}{%
\subsubsection{Subsubsection Heading
Here}\label{subsubsection-heading-here}}

Bulleted lists look like this:

\begin{itemize}
\tightlist
\item
  First bullet
\item
  Second bullet
\item
  Third bullet
\end{itemize}

Numbered lists can be added as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  First item
\item
  Second item
\item
  Third item
\end{enumerate}

The text continues here.

All figures and tables should be cited in the main text as Figure 1,
Table 1, etc.

\begin{figure}[H]
\centering
\includegraphics[width=3 cm]{logo-mdpi}
\caption{This is a figure, Schemes follow the same formatting. If there are multiple panels, they should be listed as: (\textbf{a}) Description of what is contained in the first panel. (\textbf{b}) Description of what is contained in the second panel. Figures should be placed in the main text near to the first time they are cited. A caption on a single line should be centered.}
\end{figure}

\begin{table}[H]
\caption{This is a table caption. Tables should be placed in the main text near to the first time they are cited.}
\centering
%% \tablesize{} %% You can specify the fontsize here, e.g.  \tablesize{\footnotesize}. If commented out \small will be used.
\begin{tabular}{ccc}
\toprule
\textbf{Title 1}    & \textbf{Title 2}  & \textbf{Title 3}\\
\midrule
entry 1     & data          & data\\
entry 2     & data          & data\\
\bottomrule
\end{tabular}
\end{table}

This is an example of an equation:

\begin{equation}
\mathbb{S}
\end{equation}

Example of a theorem:

\begin{Theorem}
Example text of a theorem.
\end{Theorem}

The text continues here. Proofs must be formatted as follows:

Example of a proof:

\begin{proof}[Proof of Theorem 1]
Text of the proof. Note that the phrase `of Theorem 1' is optional if it is clear which theorem is being referred to.
\end{proof}

The text continues here.

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

Authors should discuss the results and how they can be interpreted in
perspective of previous studies and of the working hypotheses. The
findings and their implications should be discussed in the broadest
context possible. Future research directions may also be highlighted.

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

This section is not mandatory, but can be added to the manuscript if the
discussion is unusually long or complex.

\hypertarget{patents}{%
\section{Patents}\label{patents}}

This section is not mandatory, but may be added if there are patents
resulting from the work reported in this manuscript.

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %% optional
% \supplementary{The following are available online at www.mdpi.com/link, Figure S1: title, Table S1: title, Video S1: title.}
%
% % Only for the journal Methods and Protocols:
% % If you wish to submit a video article, please do so with any other supplementary material.
% % \supplementary{The following are available at www.mdpi.com/link: Figure S1: title, Table S1: title, Video S1: title. A supporting video article is available at doi: link.}

\vspace{6pt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\acknowledgments{All sources of funding of the study should be
disclosed. Please clearly indicate grants that you have received in
support of your research work. Clearly state if you received funds for
covering the costs to publish in open access.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\authorcontributions{For research articles with several authors, a short
paragraph specifying their individual contributions must be provided.
The following statements should be used ``X.X. and Y.Y. conceive and
designed the experiments; X.X. performed the experiments; X.X. and Y.Y.
analyzed the data; W.W. contributed reagents/materials/analysis tools;
Y.Y. wrote the paper.'\,' Authorship must be limited to those who have
contributed substantially to the work reported.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\conflictsofinterest{`The authors declare no conflict of interest.'}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% optional
\abbreviations{The following abbreviations are used in this manuscript:\\

\noindent
\begin{tabular}{@{}ll}
MDPI & Multidisciplinary Digital Publishing Institute \\
DOAJ & Directory of open access journals \\
TLA & Three letter acronym \\
LD & linear dichroism \\
\end{tabular}}

\input{"appendix.tex"}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Citations and References in Supplementary files are permitted provided that they also appear in the reference list here.

%=====================================
% References, variant A: internal bibliography
%=====================================
%\reftitle{References}
%\begin{thebibliography}{999}
% Reference 1
%\bibitem[Author1(year)]{ref-journal}
%Author1, T. The title of the cited article. {\em Journal Abbreviation} {\bf 2008}, {\em 10}, 142--149.
% Reference 2
%\bibitem[Author2(year)]{ref-book}
%Author2, L. The title of the cited contribution. In {\em The Book Title}; Editor1, F., Editor2, A., Eds.; Publishing House: City, Country, 2007; pp. 32--58.
%\end{thebibliography}

% The following MDPI journals use author-date citation: Arts, Econometrics, Economies, Genealogy, Humanities, IJFS, JRFM, Laws, Religions, Risks, Social Sciences. For those journals, please follow the formatting guidelines on http://www.mdpi.com/authors/references
% To cite two works by the same author: \citeauthor{ref-journal-1a} (\citeyear{ref-journal-1a}, \citeyear{ref-journal-1b}). This produces: Whittaker (1967, 1975)
% To cite two works by the same author with specific pages: \citeauthor{ref-journal-3a} (\citeyear{ref-journal-3a}, p. 328; \citeyear{ref-journal-3b}, p.475). This produces: Wong (1999, p. 328; 2000, p. 475)

%=====================================
% References, variant B: external bibliography
%=====================================
\reftitle{References}
\externalbibliography{yes}
\bibliography{synth.bib}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% optional
\sampleavailability{Samples of the compounds \ldots\ldots{} are
available from the authors.}

%% for journal Sci
%\reviewreports{\\
%Reviewer 1 comments and authors’ response\\
%Reviewer 2 comments and authors’ response\\
%Reviewer 3 comments and authors’ response
%}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
